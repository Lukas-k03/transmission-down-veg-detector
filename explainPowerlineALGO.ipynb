{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Line Detection Algorithm: Step by Step Explanation\n",
    "\n",
    "## 1. Image Loading and Preprocessing\n",
    "\n",
    "```python\n",
    "img = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
    "gray = cv2.equalizeHist(gray)\n",
    "```\n",
    "\n",
    "- **Histogram Equalization**: This redistributes pixel intensities to enhance contrast. Mathematically, it transforms the histogram to be approximately uniform. For each pixel value i, the new value becomes:\n",
    "  ```\n",
    "  equalized(i) = floor((CDF(i) - CDFmin) × (L-1) / (M×N - CDFmin))\n",
    "  ```\n",
    "  Where CDF is the cumulative distribution function, M×N is image size, and L is the number of gray levels (256). This is from the slides ahahsah\n",
    "\n",
    "## 2. Edge Detection with Sobel Operator\n",
    "\n",
    "```python\n",
    "sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "abs_sobel_y = np.absolute(sobel_y)\n",
    "sobel_y_8u = np.uint8(255 * abs_sobel_y / np.max(abs_sobel_y))\n",
    "```\n",
    "\n",
    "- **Sobel Operator** is a discrete differentiation operator that computes an approximation of the gradient of the image intensity. In this case, we're detecting horizontal edges by applying the y-direction kernel.\n",
    "\n",
    "- The Sobel y-direction kernel for a 3×3 filter is:\n",
    "  ```\n",
    "  [ 1  2  1]\n",
    "  [ 0  0  0]\n",
    "  [-1 -2 -1]\n",
    "  ```\n",
    "\n",
    "- For each pixel at position (x,y), the filter response is calculated as:\n",
    "  ```\n",
    "  G_y(x,y) = ∑∑ K(i,j) * I(x+i-1, y+j-1)\n",
    "  ```\n",
    "  Where K is the kernel and I is the image ALSO from the slides ahahahahahruanrjnrgfd\n",
    "\n",
    "- **Normalization**: The `abs_sobel_y / np.max(abs_sobel_y)` normalizes values to [0,1], then multiplying by 255 scales to standard 8-bit range [0,255].\n",
    "\n",
    "## 3. Region of Interest Selection\n",
    "\n",
    "```python\n",
    "h, w = gray.shape\n",
    "margin = int(0.30 * w)\n",
    "x_start = margin\n",
    "x_end = w - margin\n",
    "cropped_edges = sobel_y_8u[:, x_start:x_end]\n",
    "```\n",
    "\n",
    "- This creates a region of interest (ROI) by taking the middle 40% of the image width (margins of 30% on each side).\n",
    "- In image coordinates, this is selecting a submatrix from the original matrix.\n",
    "\n",
    "## 4. Thresholding\n",
    "\n",
    "```python\n",
    "binary = cv2.threshold(cropped_edges, 50, 255, cv2.THRESH_BINARY)[1]\n",
    "```\n",
    "\n",
    "- **Binary Thresholding**: For each pixel value p at position (x,y):\n",
    "  ```\n",
    "  binary(x,y) = 255 if p > 50 else 0\n",
    "  ```\n",
    "- This creates a binary image where edge pixels are white (255) and non-edge pixels are black (0).\n",
    "\n",
    "## 5. Column-by-Column Pixel Analysis\n",
    "\n",
    "```python\n",
    "for x in range(binary.shape[1]):\n",
    "    edge_pixels = np.where(binary[:, x] > 0)[0]\n",
    "```\n",
    "\n",
    "- For each column in the image, we find all positions where edge pixels exist.\n",
    "- `np.where()` returns indices where the condition is true, giving us y-coordinates of all edge pixels in this column.\n",
    "\n",
    "## 6. Pixel Grouping\n",
    "\n",
    "```python\n",
    "pixel_groups = []\n",
    "current_group = [edge_pixels[0]]\n",
    "for i in range(1, len(edge_pixels)):\n",
    "    if edge_pixels[i] - edge_pixels[i-1] < 10:\n",
    "        current_group.append(edge_pixels[i])\n",
    "    else:\n",
    "        pixel_groups.append(current_group)\n",
    "        current_group = [edge_pixels[i]]\n",
    "```\n",
    "\n",
    "- This groups vertically contiguous edge pixels by checking their proximity.\n",
    "- If two consecutive pixels are less than 10 pixels apart vertically, they belong to the same group.\n",
    "- This clustering step helps identify distinct line segments in each column.\n",
    "\n",
    "## 7. Group Position Calculation\n",
    "\n",
    "```python\n",
    "group_avg_y = [sum(group) / len(group) for group in pixel_groups]\n",
    "```\n",
    "\n",
    "- For each group of pixels, we calculate the mean y-position. This represents the center of each detected line segment in the current column.\n",
    "- Mathematically, this is the arithmetic mean: μ = (∑y) / n where n is the number of pixels in the group.\n",
    "\n",
    "## 8. Phase Assignment and Tracking\n",
    "\n",
    "```python\n",
    "# First initialization\n",
    "if phase_a_avg_y is None and len(sorted_groups) >= 1:\n",
    "    phase_a_avg_y = sorted_avg_y[0]\n",
    "    phase_a_points.append((x + x_start, int(sorted_avg_y[0])))\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```python\n",
    "# Subsequent matching\n",
    "distances = []\n",
    "if phase_a_avg_y is not None and 'A' not in assigned_phases:\n",
    "    distances.append(abs(avg_y - phase_a_avg_y))\n",
    "    \n",
    "# Finding closest phase\n",
    "min_idx = np.argmin(distances)\n",
    "```\n",
    "\n",
    "- **Initial Phase Assignment**: When first encountering edge groups, we assign phases top-to-bottom (A-B-C).\n",
    "\n",
    "- **Ongoing Tracking**: For subsequent columns, we match edge groups to phases based on proximity to the running average position of each phase.\n",
    "\n",
    "- **Distance Calculation**: We compute the absolute difference between each detected group's position and the running average position of each phase: d = |y_group - y_phase_avg|\n",
    "\n",
    "- **Minimum Distance Assignment**: We assign the group to the phase with the smallest distance, provided it's within our tolerance threshold.\n",
    "\n",
    "## 9. Running Average Updates\n",
    "\n",
    "```python\n",
    "phase_a_avg_y = 0.7 * phase_a_avg_y + 0.3 * avg_y\n",
    "```\n",
    "\n",
    "- This implements an **Exponentially Weighted Moving Average (EWMA)** for phase tracking.\n",
    "- It's essentially a low-pass filter that smooths out position estimates.\n",
    "- The formula is: new_avg = α * old_avg + (1-α) * new_value, where α = 0.7 controls the weight of history.\n",
    "- This gives more weight (70%) to historical positions and less weight (30%) to the new observation, providing smoothness and continuity while still adapting to gradual changes.\n",
    "\n",
    "## 10. Drawing and Visualization\n",
    "\n",
    "```python\n",
    "# Draw points\n",
    "cv2.circle(result_img, point, 2, color, -1)\n",
    "\n",
    "# Connect points\n",
    "cv2.line(result_img, points[i-1], points[i], color, 2)\n",
    "```\n",
    "\n",
    "- This visualizes detected points and connects them to show continuous power lines.\n",
    "- Points from the same phase are connected sequentially to form polylines.\n",
    "\n",
    "## Mathematical Insights\n",
    "\n",
    "1. **Edge Detection**: The Sobel operator is essentially a finite difference approximation of the image gradient, highlighting areas of rapid intensity change.\n",
    "\n",
    "2. **Clustering**: The grouping algorithm implements a simple form of one-dimensional density-based clustering with a fixed distance threshold.\n",
    "\n",
    "3. **Phase Tracking**: The algorithm uses a combination of:\n",
    "   - Nearest neighbor matching (minimum distance assignment)\n",
    "   - Exponential smoothing (weighted running average)\n",
    "   - Threshold-based association (y_tolerance parameter)\n",
    "\n",
    "4. **Coordinate Spaces**: Note that we're working in multiple coordinate spaces:\n",
    "   - Original image coordinates\n",
    "   - Cropped ROI coordinates (shifted by x_start)\n",
    "   - Column-specific coordinates within the ROI\n",
    "\n",
    "5. **Robustness Elements**:\n",
    "   - The weighted running average prevents jumps from noise\n",
    "   - The tolerance threshold (y_tolerance) prevents misassignments\n",
    "   - Grouping nearby pixels reduces impact of noise\n",
    "   - The algorithm can handle missing phases in some columns\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
